{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H36m dataset\n",
    "\n",
    "## Overview\n",
    "加载数据集，data_3d_h36m是原始数据的positions（即3d数据，单位是米(m)），data_2d_h36m_gt是从data_3d_h36m根据相机参数投影得到的2d坐标。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D\n",
    "数据分subjects存放，一共有'S1', 'S5', 'S6', 'S7', 'S8', 'S9', 'S11'。每个subject会存放多个action，每个action对应一段数据，shape为(frames, 32, 3)，这里32是关节数，**这里的数据不是相机坐标系的位置，要得到3d坐标还需处理**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dir_path = '../data/'\n",
    "data_path = dir_path + 'data_3d_h36m.npz'\n",
    "data = np.load(data_path, allow_pickle=True)\n",
    "print(list(data.keys()))\n",
    "\n",
    "data = data['positions_3d'].item()\n",
    "print(data.keys())\n",
    "print(len(data['S1'].keys()))\n",
    "print(data['S1'].keys())\n",
    "print(data['S1']['Posing'].shape)\n",
    "print(data['S1']['Posing'][50][9])\n",
    "print(data['S1']['Posing'][100][9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 如何得到3d坐标\n",
    "\n",
    "理论部分：\\\n",
    "https://zhuanlan.zhihu.com/p/54139614 \\\n",
    "https://zhuanlan.zhihu.com/p/389653208"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['S1']['Posing'].copy()\n",
    "print(X.shape)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 相机外参\n",
    "import torch\n",
    "\n",
    "\n",
    "def wrap(func, *args, unsqueeze=False):\n",
    "    \"\"\"\n",
    "    Wrap a torch function so it can be called with NumPy arrays.\n",
    "    Input and return types are seamlessly converted.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert input types where applicable\n",
    "    args = list(args)\n",
    "    for i, arg in enumerate(args):\n",
    "        if type(arg) == np.ndarray:\n",
    "            args[i] = torch.from_numpy(arg)\n",
    "            if unsqueeze:\n",
    "                args[i] = args[i].unsqueeze(0)\n",
    "\n",
    "    result = func(*args)\n",
    "\n",
    "    # Convert output types where applicable\n",
    "    if isinstance(result, tuple):\n",
    "        result = list(result)\n",
    "        for i, res in enumerate(result):\n",
    "            if type(res) == torch.Tensor:\n",
    "                if unsqueeze:\n",
    "                    res = res.squeeze(0)\n",
    "                result[i] = res.numpy()\n",
    "        return tuple(result)\n",
    "    elif type(result) == torch.Tensor:\n",
    "        if unsqueeze:\n",
    "            result = result.squeeze(0)\n",
    "        return result.numpy()\n",
    "    else:\n",
    "        return result\n",
    "\n",
    "\n",
    "def qrot(q, v):\n",
    "    \"\"\"\n",
    "    Rotate vector(s) v about the rotation described by quaternion(s) q.\n",
    "    Expects a tensor of shape (*, 4) for q and a tensor of shape (*, 3) for v,\n",
    "    where * denotes any number of dimensions.\n",
    "    Returns a tensor of shape (*, 3).\n",
    "    \"\"\"\n",
    "    assert q.shape[-1] == 4\n",
    "    assert v.shape[-1] == 3\n",
    "    assert q.shape[:-1] == v.shape[:-1]\n",
    "\n",
    "    qvec = q[..., 1:]\n",
    "    uv = torch.cross(qvec, v, dim=len(q.shape)-1)\n",
    "    uuv = torch.cross(qvec, uv, dim=len(q.shape)-1)\n",
    "    return (v + 2 * (q[..., :1] * uv + uuv))\n",
    "\n",
    "\n",
    "def qinverse(q, inplace=False):\n",
    "    # We assume the quaternion to be normalized\n",
    "    if inplace:\n",
    "        q[..., 1:] *= -1\n",
    "        return q\n",
    "    else:\n",
    "        w = q[..., :1]\n",
    "        xyz = q[..., 1:]\n",
    "        return torch.cat((w, -xyz), dim=len(q.shape)-1)\n",
    "\n",
    "\n",
    "def world_to_camera(X, R, t):\n",
    "    Rt = wrap(qinverse, R)  # Invert rotation\n",
    "    # Rotate and translate\n",
    "    return wrap(qrot, np.tile(Rt, (*X.shape[:-1], 1)), X - t)\n",
    "\n",
    "\n",
    "cam = {\n",
    "    'orientation': [0.1407056450843811, -0.1500701755285263, -0.755240797996521, 0.6223280429840088],\n",
    "    'translation': [1841.1070556640625, 4955.28466796875, 1563.4454345703125],\n",
    "}\n",
    "for k, v in cam.items():\n",
    "    cam[k] = np.array(v)\n",
    "cam['translation'] /= 1000  # mm -> m\n",
    "Rt = wrap(qinverse, cam['orientation'])\n",
    "print(Rt.shape)\n",
    "print(Rt)\n",
    "print(X.shape)\n",
    "tmp = np.tile(Rt, (*X.shape[:-1], 1))\n",
    "print(tmp.shape)\n",
    "pos_3d = world_to_camera(X, cam['orientation'], cam['translation'])\n",
    "print(pos_3d.shape)\n",
    "print(pos_3d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从3d投影到2d\n",
    "这里有两种实现，\n",
    "project_to_2d_linear 和 project_to_2d，前者只用线性参数，后者用了非线性参数（各种畸变） "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "39dd61696b6e1fc6334e8188df1c4e4efcacf6a9ef4cab895eb1837aea6db278"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('hpe': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
